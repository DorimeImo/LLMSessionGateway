apiVersion: apps/v1
kind: Deployment
metadata:
  name: llmsessiongateway
  namespace: llmsessiongateway
spec:
  replicas: 1
  selector: { matchLabels: { app: llmsessiongateway } }
  strategy: { type: RollingUpdate, rollingUpdate: { maxSurge: 1, maxUnavailable: 0 } }
  template:
    metadata: { labels: { app: llmsessiongateway } }
    spec:
      serviceAccountName: llmsgw-sa
      securityContext:
        runAsNonRoot: true
        seccompProfile: { type: RuntimeDefault }
      containers:
      - name: api
        image: ghcr.io/you/llmsessiongateway-api:1.0.0
        imagePullPolicy: IfNotPresent
        ports: [{ name: http, containerPort: 8080 }]
        envFrom:
        - configMapRef: { name: llmsgw-config }
        - secretRef:    { name: llmsgw-secrets }
        env:
        - name: AZURE_CLIENT_ID
          value: "<UAMI_CLIENT_ID>"

        securityContext:
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
          capabilities: { drop: ["ALL"] }
        volumeMounts:
        - { name: tmp,     mountPath: /tmp }
        - { name: applogs, mountPath: /var/log/app }
        readinessProbe: { httpGet: { path: /ready,  port: http }, initialDelaySeconds: 5,  periodSeconds: 10, timeoutSeconds: 2 }
        livenessProbe:  { httpGet: { path: /health, port: http }, initialDelaySeconds: 10, periodSeconds: 15, timeoutSeconds: 2 }
        resources:
          requests: { cpu: "100m", memory: "256Mi" }
          limits:   { cpu: "500m", memory: "512Mi" }
      volumes:
      - name: tmp
        emptyDir: {}
      - name: applogs
        emptyDir: {}